---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Group Lab 3'
geometry: margin=1in
output:
  pdf_document:
    latex_engine: xelatex
  number_sections: yes
  html_document: default
  toc: yes
fontsize: 11pt
---

# U.S. traffic fatalities: 1980-2004

In this lab, you are asked to answer the question **"Do changes in traffic laws affect traffic fatalities?"**  To do so, you will conduct the tasks specified below using the data set *driving.Rdata*, which includes 25 years of data that cover changes in various state drunk driving, seat belt, and speed limit laws. 

Specifically, this data set contains data for the 48 continental U.S. states from 1980 through 2004. Various driving laws are indicated in the data set, such as the alcohol level at which drivers are considered legally intoxicated. There are also indicators for “per se” laws—where licenses can be revoked without a trial—and seat belt laws. A few economics and demographic variables are also included. The description of the each of the variables in the dataset is come with the dataste.

```{r, warning=FALSE, message=FALSE}
# Import libraries
library(ggplot2)
library(gridExtra)
library(corrplot)
library(gplots)
library(plm)
```

**Exercises:**

1. (30%) Load the data. Provide a description of the basic structure of the dataset, as we have done throughout the semester. Conduct a very thorough EDA, which should include both graphical and tabular techniques, on the dataset, including both the dependent variable *totfatrte* and the potential explanatory variables. You need to write a detailed narrative of your observations of your EDA. *Reminder: giving an "output dump" (i.e. providing a bunch of graphs and tables without description and hoping your audience will interpret them) will receive a zero in this exercise.*


### 1.1 Description of the dataset:

The dataset consists of 1200 rows and 56 columns. The data is from 1980 through 2004 and has 48 continental U.S states numbered from 1-51 with 3 states missing.For each state we have data state traffic laws,  

```{r}
# Clean up the work space before we begin
#rm(list = ls())

load("./driving.Rdata")
drivingdf <- data

desc

dim(drivingdf)
head(drivingdf)
tail(drivingdf)

```

```{r}
table(drivingdf$year)
```


```{r}
str(drivingdf)
```

**Speed Limit Variables**

```{r}
unique(drivingdf$sl55)
unique(drivingdf$sl65)
unique(drivingdf$sl70)
unique(drivingdf$sl75)
unique(drivingdf$sl70plus)
unique(drivingdf$slnone)
```

**Drinking**
```{r}
unique(drivingdf$minage)
unique(drivingdf$zerotol)
unique(drivingdf$bac10)
unique(drivingdf$bac08)
unique(drivingdf$perse)
```
**Seatbelt**

```{r}
unique(drivingdf$seatbelt)
unique(drivingdf$sbprim)
unique(drivingdf$sbsecon)
```

**Fatality**

```{r}
#totfat     
#nghtfat     
#wkndfat  
#totfatpvm
#nghtfatpvm
#wkndfatpvm
#totfatrte 
#nghtfatrte
#wkndfatrte 
```

**Demographic variables**

```{r}
#statepop
#vehicmiles
#unem
#perc14_24
```


### Data description
**year**  - Years ranging from 1980 -2004
**state** - There are 48 states with numbers from 1-51 with 3 numbers missing
**Speed Limit Variables** - sl55, sl65, sl70, sl75 and slnone  


```{r}
#Univariate analysis

hist1 <- ggplot(drivingdf, aes((totfat))) + geom_bar(fill="green") 

hist2 <- ggplot(drivingdf, aes((nghtfat))) + geom_bar(fill="green")

hist3 <- ggplot(drivingdf, aes((wkndfat))) + geom_bar(fill="green")

hist4 <- ggplot(drivingdf, aes((totfatpvm))) + geom_bar(fill="green")

hist5 <- ggplot(drivingdf, aes((nghtfatpvm))) + geom_bar(fill="green")

hist6 <- ggplot(drivingdf, aes((wkndfatpvm))) + geom_bar(fill="green")

hist7 <- ggplot(drivingdf, aes((totfatrte))) + geom_bar(fill="green")

hist8 <- ggplot(drivingdf, aes((nghtfatrte))) + geom_bar(fill="green")

hist9 <- ggplot(drivingdf, aes((wkndfatrte))) + geom_bar(fill="green")

grid.arrange(hist1, hist2, hist3, hist4, hist5, hist6, hist7, hist8, hist9, nrow = 3, ncol = 3, top="Fatalities")


```

```{r}
#bi variate analysis
boxplot1 <- ggplot(drivingdf, aes(x = year, y = totfat, fill = year)) + geom_boxplot(aes(fill = year, group = year), show.legend = FALSE)
boxplot2 <- ggplot(drivingdf, aes(x = year, y = nghtfat, fill = year)) + geom_boxplot(aes(fill = year, group = year), show.legend = FALSE)
boxplot3 <- ggplot(drivingdf, aes(x = year, y = wkndfat, fill = year)) + geom_boxplot(aes(fill = year, group = year), show.legend = FALSE)
boxplot4 <- ggplot(drivingdf, aes(x = year, y = totfatpvm, fill = year)) + geom_boxplot(aes(fill = year, group = year), show.legend = FALSE)
boxplot5 <- ggplot(drivingdf, aes(x = year, y = nghtfatpvm, fill = year)) + geom_boxplot(aes(fill = year, group = year), show.legend = FALSE)
boxplot6 <- ggplot(drivingdf, aes(x = year, y = wkndfatpvm, fill = year)) + geom_boxplot(aes(fill = year, group = year), show.legend = FALSE)
boxplot7 <- ggplot(drivingdf, aes(x = year, y = totfatrte, fill = year)) + geom_boxplot(aes(fill = year, group = year), show.legend = FALSE)
boxplot8 <- ggplot(drivingdf, aes(x = year, y = nghtfatrte, fill = year)) + geom_boxplot(aes(fill = year, group = year), show.legend = FALSE)
boxplot9 <- ggplot(drivingdf, aes(x = year, y = wkndfatrte, fill = year)) + geom_boxplot(aes(fill = year, group = year), show.legend = FALSE)

grid.arrange(boxplot1, boxplot2, boxplot3, boxplot4, boxplot5, boxplot6, boxplot7, boxplot8, boxplot9, nrow = 3, ncol = 3, top="Fatalities by Year")

```

```{r}
corrplot(cor(drivingdf[1:30]))
```


```{r}
# Density
density_plot = function(data, plotvar, title) {
  ggplot(data, aes(plotvar)) + geom_density() + ggtitle(title)
}

# Conditional Box-plot
conditional_plot = function(data, plotvar, condvar, title) {
  g <- ggplot(data, aes(as.factor(condvar), plotvar)) 
  g + geom_boxplot() + geom_jitter(width = 0.2) + ggtitle(title)
}

density_plot(drivingdf, drivingdf$totfatrte, "totfatrte")


# yIndex by year (Heterogeineity across year)
conditional_plot(drivingdf, drivingdf$totfatrte, drivingdf$year, "Totalfatrte by year")

# yIndex by country (Heterogeineity across countries)
conditional_plot(drivingdf, drivingdf$totfatrte, drivingdf$state, "Totalfatrte by State")


#scatterplot(totfatrte ~  year|state, boxplots=FALSE, smooth=TRUE, data=drivingdf)

# Heterogeineity across countries
#plotmeans(totfatrte ~ state, main="Heterogeineity across States", data=drivingdf)
plotmeans(totfatrte ~ year, main="Heterogeineity across years", data=drivingdf)

# 
coplot(totfatrte ~ year|state, type="l", data=drivingdf)
#coplot(xIndex ~ year|country, type="b", data=df)

xyplot(totfatrte ~ year | state, data=drivingdf, as.table=T)
#xyplot(xIndex ~ year | country, data=df, as.table=T)

```




2. (15%) How is the our dependent variable of interest *totfatrte* defined? What is the average of this variable in each of the years in the time period covered in this dataset? Estimate a linear regression model of *totfatrte* on a set of dummy variables for the years 1981 through 2004. What does this model explain? Describe what you find in this model. Did driving become safer over this period? Please provide a detailed explanation.

*totfatrte* defines the total fatalities per 100,000 population.**<<TODO>>**


```{r}
yearlyavg <- aggregate(totfatrte~year, drivingdf, mean)

# Printing the yearly average for total fatality rate
yearlyavg

# Plotting the yearly total fatality rate
ggplot(yearlyavg) + 
  geom_line(
    mapping = aes(x = year, y = totfatrte)
)
```



```{r}
lm.fit1 <- lm(totfatrte ~ d81+d82+d83+d84+d85+d86+d87+d88+d89+
                      d90+d91+d92+d93+d94+d95+d96+d97+d98+d99+
                      d00+d01+d02+d03+d04, data=drivingdf)
summary(lm.fit1)
```



3. (15%) Expand your model in *Exercise 2* by adding variables *bac08, bac10, perse, sbprim, sbsecon, sl70plus, gdl, perc14_24, unem, vehicmilespc*, and perhaps *transformations of some or all of these variables*. Please explain carefully your rationale, which should be based on your EDA, behind any transformation you made. If no transformation is made, explain why transformation is not needed. How are the variables *bac8* and *bac10* defined? Interpret the coefficients on *bac8* and *bac10*. Do *per se laws* have a negative effect on the fatality rate? What about having a primary seat belt law? (Note that if a law was enacted sometime within a year the fraction of the year is recorded in place of the zero-one indicator.)





```{r}

lm.fit2 <- lm(totfatrte ~ d81+d82+d83+d84+d85+d86+d87+d88+d89+
                      d90+d91+d92+d93+d94+d95+d96+d97+d98+d99+
                      d00+d01+d02+d03+d04 + bac08 + bac10 + perse + sbprim + sbsecon + sl70plus + gdl +  perc14_24 + unem + vehicmilespc, data=drivingdf)
summary(lm.fit2)

```
*bac10* is defined as the	blood alcohol limit of .10
*bac08* is defined as the	blood alcohol limit of .08

Both the variables *bac08* and *bac10*  have the negative coefficients of -2.498 and -1.418 respectively. They are statistically significant and it implies that they have a strong negative correlation to the total fatality rate.If we come up with a stricter law and decrease the blood alcohol limit to .10 then the fatalities rate decreases more.

Yes. *perse* variable has a statistically significant negative correlation with the total fatality rate. The coefficient value is -0.6201 which implies a small change in the rate.

**TODO** write up about primary seatbelt law


4. (15%) Reestimate the model from *Exercise 3* using a fixed effects (at the state level) model. How do the coefficients on *bac08, bac10, perse, and sbprim* compare with the pooled OLS estimates? Which set of estimates do you think is more reliable? What assumptions are needed in each of these models?  Are these assumptions reasonable in the current context?


```{r}

pnldata <- pdata.frame(drivingdf, c("state", "year"))

model.fe <- plm(totfatrte ~ d81+d82+d83+d84+d85+d86+d87+d88+d89+
                      d90+d91+d92+d93+d94+d95+d96+d97+d98+d99+
                      d00+d01+d02+d03+d04 + bac08 + bac10 + perse + sbprim + sbsecon + sl70plus + gdl +  perc14_24 + unem + vehicmilespc, data=pnldata, model = "within")
summary(model.fe)

```
5. (10%) Would you perfer to use a random effects model instead of the fixed effects model you built in *Exercise 4*? Please explain.


```{r}

model.re <- plm(totfatrte ~ d81+d82+d83+d84+d85+d86+d87+d88+d89+
                      d90+d91+d92+d93+d94+d95+d96+d97+d98+d99+
                      d00+d01+d02+d03+d04 + bac08 + bac10 + perse + sbprim + sbsecon + sl70plus + gdl +  perc14_24 + unem + vehicmilespc, data=pnldata, model = "random")
summary(model.re)

```

```{r}
phtest(model.fe, model.re)
```
> Fixed effect model should be used

6. (10%) Suppose that *vehicmilespc*, the number of miles driven per capita, increases by $1,000$. Using the FE estimates, what is the estimated effect on *totfatrte*? Please interpret the estimate.

The coefficient for the $vehicmilespc$ variable is 0.00094005 using the FE estimates and it is highly statistically significant. In other words, There will be an increase of 0.94 fatalities per 100k for an increase of 1000 vehicle miles driven per capita.


7. (5%) If there is serial correlation or heteroskedasticity in the idiosyncratic errors of the model, what would be the consequences on the estimators and their standard errors?

There is no serial correlation in the idiosyncratic errors of our model as shown in the p-value below. However if there is Serial correlation then it  will not affect the unbiasedness or 
consistency of OLS estimators, but it does affect their efficiency. With positive serial correlation, the OLS estimates of the standard errors will be smaller than the true standard errors. This will lead to the conclusion that the parameter estimates are more precise than they really are. There will be a tendency to reject the null hypothesis when it should not be rejected. 


```{r}
pbgtest(model.fe)
```











